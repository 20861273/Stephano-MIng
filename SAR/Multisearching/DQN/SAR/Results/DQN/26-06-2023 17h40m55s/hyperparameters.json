{"number of drones": 1, "training type": "centralized", "agent type": "DQN", "learning rate": [0.0001], "discount rate": [0.8, 0.9, 0.99], "epsilon": [[0.01, 0.01, 0.01]], "training sessions": 1, "episodes": 10000, "positive rewards": [1], "positive exploration rewards": [0], "negative rewards": [1], "negative step rewards": [0.01], "max steps": [200], "n actions": 4, "env size": "8x8", "encoding": "image", "input dims": [2, 8, 8], "lidar": true, "batch size": 64, "mem size": 100000, "replace": 1000, "channels": [16, 32], "kernel": [2, 2], "stride": [1, 1], "fc dims": [32, 64, 32], "prioritized": true, "starting beta": 0.5, "device": 0, "allow windowed revisiting": false, "curriculum learning": {"sparse reward": true, "collisions": false}, "reward system": {"find goal": true, "coverage": false}}